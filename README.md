Quatrain
=======
Quatrain (Question Answering for Patch Correctness Evaluation), a supervised learning approach that exploits a deep NLP model to classify the
relatedness of a bug report with a patch description.
```bibtex
@article{tian2021is,
  title={Is this Change the Answer to that Problem? Correlating Descriptions of Bug and Code Changes for Evaluating Patch Correctness},
}
```

## Ⅰ) Experiment

To obtain experimental results of the paper, execute `run.py` with specific parameter:

### A) Sec. 2.2 
  1. **Figure 3:** Distributions of Euclidean distances between bug and patch descriptions.
```
python run.py hypothesis
```

### B) Sec. 5.1 (RQ1) 
  1. **Figure 6:** Distribution of Patches in Train and Test Data. 
  2. **Table 2.:** Confusion matrix of Quatrain prediction.
```
python run.py RQ1
```
  3. **F1:** F1 score by re-balancing the test data.
```
python run.py RQ1 balance
```  

### C) Sec. 5.2 (RQ2)
#### RQ 2.1
  1. **Figure 7:**  Impact of length of patch description to prediction.
```
python run.py RQ2.1
```
#### RQ 2.2
  2. **Figure 8:**  The distribution of probability of patch correctness
on original and random bug report.
  3. **The dropped +Recall:**  22% (242/1091) of developer patches, which were previously predicted as correct, are no longer recalled by Quatrain after they have been associated to a random bug report.
```
python run.py RQ2.2
```
#### RQ 2.3
  4. **Figure 9:**   Impact of distance between generated patch descrip-
tion to ground truth on prediction performance.
  5. **The dropped +Recall:**  The metric (+Recall) drops by 40 percentage points to 44\% when the developer-written descriptions are replaced with CodeTrans-generated descriptions.
```
python run.py RQ2.3
```
  6. **The dropped AUC:**  we evaluated Quatrain in a setting where all developer commit messages were replaced with generated descriptions: the AUC metric dropped by 12 percentage points to 0.770, confirming our findings.
```
python run.py RQ1 generate
```

### D) Sec. 5.3 (RQ3)
#### Sec. 5.3.1 (Static approaches)
  1. **Table 3:** Quatrain vs a DL-based patch classifie.
  2. **New identification:**  Among 9135 patches, our approach identifies 7591 patches, of which 2559 patches cannot be identified by Tian et al.'s approach (RF).
```
python run.py RQ3 DL
```
  3. **Table 4:** Quatrain vs BATS.
  4. **New identification:**  183 out of 342 patches are exclusively identified by Quatrain.
```
python run.py RQ3 BATS
```

#### Sec. 5.3.2 (Dynamic approach)
  1. **Table 5:** Quatrain vs (execution-based) PATCH-SIM.
  2. **New identification:**  Most of the patches (1867/3128) that we identify are not correctly predicted by PATCH-SIM.
```
python run.py RQ3 PATCHSIM
```

## Ⅱ) Dataset
* **BugReport:** Bug reports for Defects4j, Bugsjar, Bears. Structured as `bug-id $$ bug report summary $$ bug report description`.
  1. bug report summary: title for bug issue  
  2. bug report description: detailed description for bug issue
* **CommitMessage:** Commit messages written by developer or generated by CodeTrans. Structured as `bug-id: commit message` in json file.
* **bugreport_patch.txt:** Pairs of Bug report & Commit message. Structured as `bug-id $$ bug report summary $$ bug report description $$ patchId $$ patch description $$ label`
* **Patches.zip:** collected patches for Defects4J, Bears, Bugs.jar

## Ⅲ) Requirements

[//]: # (### deduplicate.py)
[//]: # (deduplicating same patches.)